{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HyA-XjSe9-M3",
        "lyM7s7W48Zf_",
        "WjtU_WCB86_d"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOvpQUVQtmLMYghTxKjVlky",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiwi2kiwi/Doublet_detection/blob/main/preparing_for_doublet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial:\n",
        "To train the network, run the following cells:\n",
        "\n",
        "Eigener Dataloader 103 size\\\n",
        "Loading data from h5ad\\\n",
        "Architecture\\\n",
        "Early stopping\\\n",
        "Training"
      ],
      "metadata": {
        "id": "6fy0X4x8cnzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important imports"
      ],
      "metadata": {
        "id": "mUuYivKAa_CV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install 'fsspec>=0.3.3'\n",
        "!python -m pip install dask[dataframe] --upgrade  "
      ],
      "metadata": {
        "id": "rqq2whjHa99z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the data\n",
        "We want the doubletannotation.csv as the label file.\n",
        "The pbmc_expr.csv can be the x \n",
        "doubletannotation.csv can be the y"
      ],
      "metadata": {
        "id": "HyA-XjSe9-M3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "test_data = 0\n",
        "train_data = 0\n",
        "val_data = 0\n"
      ],
      "metadata": {
        "id": "JZdBbuAHBWEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import required modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from dask import dataframe as df1\n",
        "  \n",
        "# time taken to read data\n",
        "s_time_dask = time.time()\n",
        "dask_df = df1.read_csv('pbmc_expr.csv', assume_missing=True)\n",
        "e_time_dask = time.time()\n",
        "  \n",
        "print(\"Read with dask: \", (e_time_dask-s_time_dask), \"seconds\")\n",
        "  \n",
        "# data\n",
        "dask_df.head(1)"
      ],
      "metadata": {
        "id": "LQVe8B7ZEUaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialect = 0\n",
        "with open('pbmc_expr.csv', newline='') as csvfile:\n",
        "    dialect = csv.Sniffer().sniff(csvfile.read(1024))\n",
        "    csvfile.seek(0)\n",
        "    print(csvfile.seek(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arTvMgtzBU01",
        "outputId": "64607e23-3cab-4924-fd0f-8ede9eb35580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import x\n",
        "with open('pbmc_expr.csv', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
        "    reader\n",
        "    for row in reader:\n",
        "        print(', '.join(row))"
      ],
      "metadata": {
        "id": "Gn9LXAiRCSLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eigener Dataloader 4 size"
      ],
      "metadata": {
        "id": "-uCWK1K2WXua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomDataloaderold(Dataset):\n",
        "    def __init__(self, dast):\n",
        "        self.dast = dast\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.dast.index.stop\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        entry = self.dast.iloc[idx]\n",
        "        if type(idx) == slice:\n",
        "          xent = np.vstack(entry.values[:,2:6]).astype(np.float)\n",
        "          x = torch.from_numpy(xent).float()\n",
        "          yent = np.vstack(entry.values[:,6:]).astype(np.float)\n",
        "          y = torch.from_numpy(yent).float()\n",
        "        else:\n",
        "          x = torch.tensor(entry[2:6]).float()\n",
        "          y = torch.tensor([float(int(i)) for i in entry[6:]]).float()\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "zXK8-FfVWXHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eigener Dataloader 103 size"
      ],
      "metadata": {
        "id": "-38aiY4aPjsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomDataloader(Dataset):\n",
        "    def __init__(self, dast):\n",
        "        self.dast = dast\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.dast.index.stop\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        entry = self.dast.iloc[idx]\n",
        "        if type(idx) == slice:\n",
        "          xent = np.vstack(entry.values[:,:-3]).astype(np.float)\n",
        "          x = torch.from_numpy(xent).float()\n",
        "          yent = np.vstack(entry.values[:,-3:]).astype(np.float)\n",
        "          y = torch.from_numpy(yent).float()\n",
        "        else:\n",
        "          x = torch.tensor(entry[:-3]).float()\n",
        "          y = torch.tensor([float(int(i)) for i in entry[-3:]]).float()\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "WoZmwe8lPm1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading data from csv"
      ],
      "metadata": {
        "id": "SQObqJOJ8zhe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9t89EATkcXW",
        "outputId": "67e73f74-b708-4379-bd4f-98ba1f086dff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "(362, 9)\n",
            "(290, 9)\n",
            "(300, 9)\n",
            "[[4865 'CGTCATTGTAGGTGTC.1' 0.773191750049591 ... True False False]\n",
            " [6858 'GCCGTGAGTGGTTCCC.1' 0.0421629399061203 ... False False True]\n",
            " [6681 'GCACTAAGTGGATTAT.1' 0.732089161872864 ... False True False]\n",
            " ...\n",
            " [1556 'AGCAACAAGGGTGAAC.1' 0.890693664550781 ... False True False]\n",
            " [2038 'AGTACGCGTTTCCGGC.1' 0.954596340656281 ... True False False]\n",
            " [4684 'CGGAATCGTTCCGGGA.1' 0.732701778411865 ... True False False]]\n",
            "     idxs                  V1    bcds_s          cxds_s   dbf_s     chord  \\\n",
            "0    4865  CGTCATTGTAGGTGTC.1  0.773192   806126.806729  0.6125 -1.196678   \n",
            "1    6858  GCCGTGAGTGGTTCCC.1  0.042163   207762.742497   0.025 -1.992952   \n",
            "2    6681  GCACTAAGTGGATTAT.1  0.732089   279032.772917   0.175 -2.065139   \n",
            "3    6855  GCCGTGAGTCAGTAAT.1  0.915708  1151176.904928  0.6125 -1.316453   \n",
            "4    4976  CTAAAGCTCATAGCCG.1  0.020389   127844.357496   0.025 -1.994257   \n",
            "..    ...                 ...       ...             ...     ...       ...   \n",
            "947  1829  AGGATCCGTGGAGCAA.1  0.745182   420345.627035  0.5625 -1.711118   \n",
            "948  1095  ACGAATCTCTTACTCG.1   0.08631   257386.647319  0.0125 -1.987088   \n",
            "949  1556  AGCAACAAGGGTGAAC.1  0.890694    497204.83353  0.5875 -1.714032   \n",
            "950  2038  AGTACGCGTTTCCGGC.1  0.954596   661410.159517  0.5375 -1.531838   \n",
            "951  4684  CGGAATCGTTCCGGGA.1  0.732702   711655.272112    0.65 -1.134221   \n",
            "\n",
            "    heterotypic homotypic singlet  \n",
            "0          True     False   False  \n",
            "1         False     False    True  \n",
            "2         False      True   False  \n",
            "3          True     False   False  \n",
            "4         False     False    True  \n",
            "..          ...       ...     ...  \n",
            "947       False      True   False  \n",
            "948       False     False    True  \n",
            "949       False      True   False  \n",
            "950        True     False   False  \n",
            "951        True     False   False  \n",
            "\n",
            "[952 rows x 9 columns]\n",
            "Training data: <__main__.CustomDataloader object at 0x7f88f9e0e610>\n",
            "Validation data: <__main__.CustomDataloader object at 0x7f88f9e0e9d0>\n",
            "Testing data: <__main__.CustomDataloader object at 0x7f88f9e1dc50>\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# import y and x\n",
        "import csv\n",
        "import pandas as pd\n",
        "dataset_read = pd.read_csv('Doubletannotation.csv')  \n",
        "\n",
        "# trimming the dataframe\n",
        "dataset_read = dataset_read[[\"V1\",\"bcds_s\",\"cxds_s\",\"dbf_s\",\"chord\",\"heterotypic\",\"homotypic\",\"singlet\"]]\n",
        "\n",
        "\n",
        "tempset = dataset_read\n",
        "train_split = tempset.sample(frac=0.8).reset_index()\n",
        "val_split = tempset.sample(frac=0.5).reset_index()\n",
        "test_split = tempset.sample(frac=1).reset_index()\n",
        "\n",
        "tt = train_split.to_numpy()\n",
        "t0 = np.where(tt[:,0+6] == True)\n",
        "t1 = np.where(tt[:,1+6] == True)\n",
        "t2 = np.where(tt[:,2+6] == True)\n",
        "t0set = tt[t0]\n",
        "t1set = tt[t1]\n",
        "t2set = tt[t2[0][:300]]\n",
        "print(t0set.shape)\n",
        "print(t1set.shape)\n",
        "print(t2set.shape)\n",
        "tset = np.concatenate((t0set, t1set), axis=0)\n",
        "tset = np.concatenate((tset, t2set), axis=0)\n",
        "np.random.shuffle(tset)\n",
        "print(tset)\n",
        "tset = pd.DataFrame(tset, columns=[\"idxs\",\"V1\",\"bcds_s\",\"cxds_s\",\"dbf_s\",\"chord\",\"heterotypic\",\"homotypic\",\"singlet\"])\n",
        "print(tset)\n",
        "\n",
        "\n",
        "train_data = CustomDataloader(tset)#train_split)\n",
        "val_data = CustomDataloader(val_split)\n",
        "test_data = CustomDataloader(test_split)\n",
        "\n",
        "loaders = {\n",
        "    'train' : train_data, #torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1),\n",
        "    'val' : val_data, #torch.utils.data.DataLoader(val_data, batch_size=100, shuffle=True, num_workers=1),\n",
        "    'test'  : test_data #torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1),\n",
        "}\n",
        "\n",
        "\n",
        "print(\"Training data:\" ,train_data)\n",
        "print(\"Validation data:\" ,val_data)\n",
        "print(\"Testing data:\" ,test_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data from h5ad"
      ],
      "metadata": {
        "id": "yfvskbXcFL6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# import y and x\n",
        "import csv\n",
        "import pandas as pd\n",
        "dataset_read = pd.read_csv('pbmc_hvg_12012_100.csv')  \n",
        "\n",
        "clist = []\n",
        "\n",
        "\n",
        "for index, row in dataset_read.iterrows():\n",
        "  if row[-1] == \"singlet\":\n",
        "    clist.append([False, False, True])\n",
        "  if row[-1] == \"homo\":\n",
        "    clist.append([False, True, False])\n",
        "  if row[-1] == \"hetero\":\n",
        "    clist.append([True, False, False])\n",
        "\n",
        "classes = pd.DataFrame(data = np.array(clist), columns=[\"hetero\",\"homo\",\"singlet\"])\n",
        "print(sum(classes[\"hetero\"]))\n",
        "print(sum(classes[\"homo\"]))\n",
        "print(sum(classes[\"singlet\"]))\n",
        "# print(classes)\n",
        "\n",
        "print(dataset_read.shape)\n",
        "dataset_read = dataset_read.drop([\"Unnamed: 0\",'obs',\"cell_type\"], axis=1)\n",
        "print(dataset_read.shape)\n",
        "dataset_read = dataset_read.join(classes)\n",
        "print(dataset_read.shape)\n",
        "\n",
        "\n",
        "tempset = dataset_read\n",
        "train_split = tempset.sample(frac=0.8)\n",
        "tempset = tempset.drop(train_split.index)\n",
        "val_split = tempset.sample(frac=0.5)\n",
        "tempset = tempset.drop(val_split.index)\n",
        "test_split = tempset.sample(frac=1)\n",
        "# tempset = tempset.drop(test_split.index)\n",
        "\n",
        "train_split.reset_index()\n",
        "val_split.reset_index()\n",
        "test_split.reset_index()\n",
        "\n",
        "tt = train_split.to_numpy()\n",
        "t0 = np.where(tt[:,-3] == True)\n",
        "t1 = np.where(tt[:,-2] == True)\n",
        "t2 = np.where(tt[:,-1] == True)\n",
        "t0set = tt[t0]\n",
        "t1set = tt[t1]\n",
        "t2set = tt[t2[0][:400]]\n",
        "print(t0set.shape)\n",
        "print(t1set.shape)\n",
        "print(t2set.shape)\n",
        "tset = np.concatenate((t0set, t1set), axis=0)\n",
        "tset = np.concatenate((tset, t2set), axis=0)\n",
        "temp_var = tset\n",
        "# tset = tset[:,1:] # eliminate index column\n",
        "np.random.shuffle(tset)\n",
        "\n",
        "tset = pd.DataFrame(tset, columns=dataset_read.columns.values)#[1:])\n",
        "# print(tset.columns.values)\n",
        "\n",
        "# print(val_split.columns.values)\n",
        "# val_split = val_split.drop([\"index\"], axis=1)\n",
        "# test_split = test_split.drop([\"index\"], axis=1)\n",
        "\n",
        "print(tset.shape)\n",
        "\n",
        "train_data = CustomDataloader(tset)#train_split)\n",
        "val_data = CustomDataloader(val_split)\n",
        "test_data = CustomDataloader(test_split)\n",
        "\n",
        "loaders = {\n",
        "    'train' : train_data, #torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1),\n",
        "    'val' : val_data, #torch.utils.data.DataLoader(val_data, batch_size=100, shuffle=True, num_workers=1),\n",
        "    'test'  : test_data #torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1),\n",
        "}\n",
        "\n",
        "\n",
        "print(\"Training data:\" ,train_data)\n",
        "print(\"Validation data:\" ,val_data)\n",
        "print(\"Testing data:\" ,test_data)\n",
        "\n",
        "\n",
        "print(\"Training data:\" ,tset.shape)\n",
        "print(\"Validation data:\" ,val_split.shape)\n",
        "print(\"Testing data:\" ,test_split.shape)\n",
        "\n",
        "print(loaders[\"train\"][0][0].shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "GC8fWQUnFPQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architectur\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i1lClAZD7oh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "'''\n",
        "in_channels (int) — Number of channels in the input image\n",
        "\n",
        "out_channels (int) — Number of channels produced by the convolution\n",
        "\n",
        "kernel_size (int or tuple) — Size of the convolving kernel\n",
        "\n",
        "stride (int or tuple, optional) — Stride of the convolution. Default: 1\n",
        "\n",
        "padding (int or tuple, optional) — Zero-padding added to both sides of the input. Default: 0\n",
        "\n",
        "padding_mode (string, optional) — ‘zeros’, ‘reflect’, ‘replicate’ or ‘circular’. Default: ‘zeros’\n",
        "\n",
        "dilation (int or tuple, optional) — Spacing between kernel elements. Default: 1\n",
        "\n",
        "groups (int, optional) — Number of blocked connections from input channels to output channels. Default: 1\n",
        "\n",
        "bias (bool, optional) — If True, adds a learnable bias to the output. Default: True\n",
        "'''\n",
        "\n",
        "\n",
        "# https://medium.com/@nutanbhogendrasharma/pytorch-convolutional-neural-network-with-mnist-dataset-4e8a4265e118\n",
        "\n",
        "# hier gehts weiter\n",
        "\n",
        "import torch.nn as nn\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(         \n",
        "            nn.Conv2d(\n",
        "                in_channels=1,              \n",
        "                out_channels=16,            \n",
        "                kernel_size=5,              \n",
        "                stride=1,                   \n",
        "                padding=2,),                              \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=2),)\n",
        "        self.conv2 = nn.Sequential(         \n",
        "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(2),)\n",
        "        # fully connected layer, output 10 classes\n",
        "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "        x = x.view(x.size(0), -1)       \n",
        "        output = self.out(x)\n",
        "        return output#, x    # return x for visualization\n",
        "\n",
        "\n",
        "\n",
        "# Create ANN Model\n",
        "class ANNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        # super(ANNModel, self).__init__()\n",
        "        super().__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(input_size, 64) \n",
        "        self.fc2 = nn.Linear(64, 8)\n",
        "        self.fc3 = nn.Linear(8, 8)\n",
        "        self.fc4 = nn.Linear(8, 8)\n",
        "        self.fcend = nn.Linear(8, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # print(x.size())\n",
        "        # print(x)\n",
        "        # x = x.view(x.size(0), -1)       \n",
        "        out = self.fc1(x)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.fc4(out)\n",
        "        out = self.fcend(out)\n",
        "        out = self.sig(out)\n",
        "        # out = self.fc1(x)\n",
        "        # out = self.fc2(out)\n",
        "        # out = self.fc3(out)\n",
        "        return out#.to(torch.float64)"
      ],
      "metadata": {
        "id": "qhVHZ3LC7nm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testt = torch.tensor([[[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3]],[[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3]]])\n",
        "print(testt)\n",
        "print(testt.size())\n",
        "print(testt.view(6,1))"
      ],
      "metadata": {
        "id": "0pFQ9Z1aVQRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Early Stopping"
      ],
      "metadata": {
        "id": "lyM7s7W48Zf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0.001, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "        self.best_model = 0\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Accuracy increased ({1-self.val_loss_min:.6f} --> {1-val_loss:.6f}).  Saving model ...')\n",
        "        self.best_model = model\n",
        "        #torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "YbnZC1HPqRoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training debugging"
      ],
      "metadata": {
        "id": "WjtU_WCB86_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "NeuralNet = ANNModel(4,3)\n",
        "    # print(nnet)\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "NeuralNet.train()\n",
        "\n",
        "# initialize the early_stopping object\n",
        "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
        "    \n",
        "# loss\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(NeuralNet.parameters(), lr = 0.01)   \n",
        "\n",
        "\n",
        "# Train the model\n",
        "total_step = len(loaders['train'])\n",
        "        \n",
        "for epoch in range(num_epochs):\n",
        "    NeuralNet.train()\n",
        "    print(epoch)\n",
        "    for images, labels in loaders['train']:\n",
        "        # gives batch data, normalize x when iterate train_loader\n",
        "        b_x = Variable(images)   # batch x\n",
        "        b_y = Variable(labels)   # batch y\n",
        "        \n",
        "        output = NeuralNet(b_x.float())\n",
        "                  \n",
        "        loss = loss_func(output, b_y)\n",
        "            \n",
        "        # clear gradients for this training step   \n",
        "        optimizer.zero_grad()           \n",
        "            \n",
        "        # backpropagation, compute gradients \n",
        "        loss.backward()    \n",
        "        # apply gradients             \n",
        "        optimizer.step()                \n",
        "        pass\n",
        "    NeuralNet.eval()\n",
        "    for data, labels in loaders['val']:\n",
        "      test_output = NeuralNet(data.float())\n",
        "      pred_y = torch.max(test_output,-1)[1]\n",
        "      true_y = torch.max(labels,-1)[1]\n",
        "      accuracy = int((pred_y == true_y).item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch.max(test_output)\n",
        "test_output\n",
        "\n",
        "# outputs = [0,0,0]\n",
        "# print([int(i) for i in (test_output>=0.5).tolist()])\n",
        "# outputs[test_output >= 0.5] = 1\n",
        "# outputs[test_output < 0.5] = 0\n",
        "pred_y = torch.max(test_output,-1)[1]\n",
        "true_y = torch.max(labels,-1)[1]\n",
        "accuracy = int((pred_y == true_y).item())\n",
        "print(pred_y)\n",
        "print(true_y)\n",
        "print((pred_y == true_y).item())\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "JxBEeFcffV9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NeuralNet = ANNModel(4,3)\n",
        "NeuralNet.train()\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(NeuralNet.parameters(), lr = 0.01)   \n",
        "\n",
        "point1, target1 = loaders[\"train\"][0:2]\n",
        "output = NeuralNet(point1.float())\n",
        "loss = loss_func(output, target1)\n",
        "# clear gradients for this training step   \n",
        "NeuralNet.zero_grad()   \n",
        "\n",
        "# print(loss)\n",
        "print('fc1.weight before backward')\n",
        "print(NeuralNet.fc1.weight[0])\n",
        "loss.backward()\n",
        "print('fc1.weight after backward')\n",
        "print(NeuralNet.fc1.weight[0])            \n",
        "optimizer.step()  \n",
        "print('fc1.weight after step')\n",
        "print(NeuralNet.fc1.weight[0])            \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKzfYXWXl7fl",
        "outputId": "5a6cf9b1-81ef-413f-9a0b-9d99ff52282b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc1.weight before backward\n",
            "tensor([-0.3939,  0.0626, -0.4104, -0.1777], grad_fn=<SelectBackward0>)\n",
            "fc1.weight after backward\n",
            "tensor([-0.3939,  0.0626, -0.4104, -0.1777], grad_fn=<SelectBackward0>)\n",
            "fc1.weight after step\n",
            "tensor([-0.3939,  0.0626, -0.4104, -0.1777], grad_fn=<SelectBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "NeuralNet = ANNModel(4,3)\n",
        "NeuralNet.train()\n",
        "criterion = nn.MSELoss()\n",
        "print(loaders[\"train\"][0:2])\n",
        "unpack = loaders[\"train\"]\n",
        "print(unpack[:])\n",
        "point1, target1 = loaders[\"train\"][0:2]\n",
        "# create your optimizer\n",
        "optimizer = optim.SGD(NeuralNet.parameters(), lr=0.01)\n",
        "print(len(loaders[\"test\"]))\n",
        "\n",
        "# in your training loop:\n",
        "print('fc1.weight before backward')\n",
        "print(NeuralNet.fc1.weight[0])\n",
        "optimizer.zero_grad()   # zero the gradient buffers\n",
        "output = NeuralNet(point1)\n",
        "print(output)\n",
        "print(target1)\n",
        "loss = criterion(output, target1)\n",
        "test = NeuralNet.fc1.bias\n",
        "# print(\"gradient: \", NeuralNet.fc1.bias)\n",
        "loss.backward()\n",
        "optimizer.step()    # Does the update\n",
        "print('fc1.weight after step')\n",
        "print(NeuralNet.fc1.weight[0]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "a2D6RJdfq9Kx",
        "outputId": "b8e6ad72-82e6-4d6d-974b-b1b909c8db91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[ 2.7279e-02,  6.8598e+04,  2.5000e-02, -1.9943e+00],\n",
            "        [ 3.1351e-02,  1.3335e+05,  1.1250e-01, -1.9835e+00]],\n",
            "       dtype=torch.float64), tensor([[0., 0., 1.],\n",
            "        [0., 0., 1.]], dtype=torch.float64))\n",
            "(tensor([[ 2.7279e-02,  6.8598e+04,  2.5000e-02, -1.9943e+00],\n",
            "        [ 3.1351e-02,  1.3335e+05,  1.1250e-01, -1.9835e+00],\n",
            "        [ 5.7130e-02,  2.1423e+05,  2.2500e-01, -1.9150e+00],\n",
            "        ...,\n",
            "        [ 4.5890e-02,  2.0553e+05,  0.0000e+00, -1.9908e+00],\n",
            "        [ 2.1363e-02,  2.7655e+05,  2.7500e-01, -1.8708e+00],\n",
            "        [ 4.5804e-02,  1.8010e+05,  3.7500e-02, -1.9908e+00]],\n",
            "       dtype=torch.float64), tensor([[0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        ...,\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.]], dtype=torch.float64))\n",
            "2402\n",
            "fc1.weight before backward\n",
            "tensor([-0.4072,  0.0744, -0.0804, -0.4936], grad_fn=<SelectBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-204-dc639016a48b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeuralNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# zero the gradient buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-66465b3aefee>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = torch.tensor([[1,0],[0,1]])\n",
        "np.where(test[:1] == 1)\n",
        "#[where torch.tensor([1,0])[0] == 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1YtaKgRx1bm",
        "outputId": "092a06fe-0d2f-491a-dc31-b3d16ac8ff73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0]), array([0]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = torch.tensor([[0,0,1],[0,0,1],[0,0,1],[0,0,1],[0,0,1],[0,0,1],[0,0,1],[0,0,1],\n",
        "                     [0,1,0],[0,1,0],[0,1,0],[0,1,0],[0,1,0],[0,1,0],[0,1,0],[0,1,0],\n",
        "                     [1,0,0],[1,0,0],[1,0,0],[1,0,0],[1,0,0],[1,0,0],[1,0,0],[1,0,0]])\n",
        "\n",
        "prediction = torch.tensor([[1,0,0],[0,0,1],[0,0,1],[0,0,1],[0,0,1],[0,0,1],[0,0,1],[0,0,1],\n",
        "                          [0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[0,1,0],[0,1,0],[0,1,0],\n",
        "                          [0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0],[1,0,0],[1,0,0],[1,0,0]])\n",
        "\n",
        "indices_class0 = np.where(label[:0] == 1)\n",
        "label_class0 = label[indices_class0]\n",
        "prediction_class0 = prediction[indices_class0]\n",
        "pred_y0 = torch.max(prediction_class0,-1)[1]\n",
        "true_y0 = torch.max(label_class0,-1)[1]\n",
        "accuracy0 = int((pred_y0 == true_y0).item())\n",
        "\n",
        "indices_class1 = np.where(label[:1] == 1)\n",
        "label_class1 = label[indices_class1]\n",
        "prediction_class1 = prediction[indices_class1]\n",
        "pred_y1 = torch.max(prediction_class1,-1)[1]\n",
        "true_y1 = torch.max(label_class1,-1)[1]\n",
        "accuracy1 = int((pred_y1 == true_y1).item())\n",
        "\n",
        "indices_class2 = np.where(label[:2] == 1)\n",
        "label_class2 = label[indices_class2]\n",
        "prediction_class2 = prediction[indices_class2]\n",
        "pred_y2 = torch.max(prediction_class2,-1)[1]\n",
        "true_y2 = torch.max(label_class2,-1)[1]\n",
        "accuracy2 = int((pred_y2 == true_y2).item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "DQn6lVqzwUay",
        "outputId": "a3331c2a-73c2-4116-e202-9ca9d202484b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-8678919bc767>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    indices_class0 = [where label[0] == 1]\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "x1,y1 = loaders['train'][0]\n",
        "x2,y2 = loaders['train'][1]\n",
        "x3,y3 = loaders['train'][2]\n",
        "model = nn.Linear(4, 3)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Run training\n",
        "niter = 10\n",
        "for _ in range(0, niter):\n",
        "\toptimizer.zero_grad()\n",
        "\tpredictions = model(x)\n",
        "\tloss = loss_fn(predictions, t)\n",
        "\tloss.backward()\n",
        "\toptimizer.step()\n",
        "\n",
        "\tprint(\"-\" * 10)\n",
        "\tprint(\"learned a = {}\".format(list(model.parameters())[0].data[0, 0]))\n",
        "\tprint(\"learned b = {}\".format(list(model.parameters())[1].data[0]))"
      ],
      "metadata": {
        "id": "O--Jue025Hxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "x1,y1 = loaders['train'][0:10]\n",
        "x2,y2 = loaders['train'][1]\n",
        "x3,y3 = loaders['train'][2]\n",
        "NeuralNet = ANNModel(4,3)\n",
        "# NeuralNet.train()\n",
        "optimizer = optim.Adam(NeuralNet.parameters(), lr = 0.01) \n",
        "criterion = nn.MSELoss()#weight=torch.tensor([1,1,0.02]))\n",
        "\n",
        "\n",
        "weight_before = NeuralNet.fc1.weight[0]\n",
        "# print(list(NeuralNet.parameters())[0].clone())\n",
        "optimizer.zero_grad()\n",
        "output = NeuralNet(x1)\n",
        "# print(output)\n",
        "loss = criterion(output, y1)\n",
        "# print(x1,y1)\n",
        "# print(loss.item())\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "weight_after = NeuralNet.fc1.weight[0]\n",
        "# print(weight_after-weight_before)\n",
        "# print(list(NeuralNet.parameters())[0].clone())\n",
        "\n",
        "print(y1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(3):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y1[:, i].detach().numpy(), output[:, i].detach().numpy())\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y1.detach().numpy().ravel(), output.detach().numpy().ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(\n",
        "    fpr[2],\n",
        "    tpr[2],\n",
        "    color=\"darkorange\",\n",
        "    lw=lw,\n",
        "    label=\"ROC curve (area = %0.2f)\" % roc_auc[2],\n",
        ")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver operating characteristic example\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "d9tMg-q4wzz-",
        "outputId": "b1fcd4b5-a826-4318-973d-5d61f5defc16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 1., 0.],\n",
            "        [1., 0., 0.],\n",
            "        [0., 0., 1.],\n",
            "        [1., 0., 0.],\n",
            "        [1., 0., 0.],\n",
            "        [0., 0., 1.],\n",
            "        [1., 0., 0.],\n",
            "        [0., 1., 0.]])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "jWDIU0oLfOMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# useful code \n",
        "def acc_for_class(let_class, labels, predictions):\n",
        "  indices_class = np.where(labels[:,let_class] == 1)\n",
        "  label_class = labels[indices_class]\n",
        "  prediction_class = predictions[indices_class]\n",
        "  # print(prediction_class.shape)\n",
        "  # print(label_class.shape)\n",
        "  pred_y = torch.max(prediction_class,-1)[1]\n",
        "  true_y = torch.max(label_class,-1)[1]\n",
        "  accuracy = sum(pred_y == true_y).item()/pred_y.__len__()\n",
        "  return accuracy\n",
        "\n",
        "def save_csv(data, name):\n",
        "  t_np = data.numpy() #convert to Numpy array\n",
        "  df = pd.DataFrame(t_np) #convert to a dataframe\n",
        "  df.to_csv(name+\".csv\",index=False) #save to file\n",
        "\n",
        "def to_strings(matrix):\n",
        "  strings = []\n",
        "  for i in matrix:\n",
        "    if i[0]:\n",
        "      strings.append(\"hetero\")\n",
        "    if i[1]:\n",
        "      strings.append(\"homo\")\n",
        "    if i[2]:\n",
        "      strings.append(\"singlet\")\n",
        "  return strings"
      ],
      "metadata": {
        "id": "6EMb872L2lKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "in_channels=1: because our input is a grayscale image.\n",
        "\n",
        "Stride: is the number of pixels to pass at a time when sliding the convolutional kernel.\n",
        "\n",
        "Padding: to preserve exactly the size of the input image, it is useful to add a zero padding on the border of the image.\n",
        "\n",
        "kernel_size: we need to define a kernel which is a small matrix of size 5 * 5. To perform the convolution operation, we just need to slide the kernel along the image horizontally and vertically and do the dot product of the kernel and the small portion of the image.\n",
        "\n",
        "The forward() pass defines the way we compute our output using the given layers and functions.\n",
        "'''\n",
        "import torch.nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def train(num_epochs, NeuralNet, loaders):\n",
        "    \n",
        "    NeuralNet.train()\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
        "    \n",
        "\n",
        "    total_step = len(loaders['train'])\n",
        "    _, labs = loaders['train'][:]\n",
        "    total_step\n",
        "    print(1-sum(labs[:,0])/total_step)\n",
        "    print(1-sum(labs[:,1])/total_step)\n",
        "    print(1-sum(labs[:,2])/total_step)\n",
        "\n",
        "    # optimizer\n",
        "    optimizer = optim.Adam(NeuralNet.parameters(), lr = 0.002)   \n",
        "\n",
        "    # loss\n",
        "    criterion = nn.MSELoss()#CrossEntropyLoss(weight=torch.tensor([1-sum(labs[:,0])/total_step, 1-sum(labs[:,1])/total_step, 1-sum(labs[:,2])/total_step]))\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(num_epochs):\n",
        "        NeuralNet.train()\n",
        "        print(epoch)\n",
        "        for images, labels in loaders['train']:\n",
        "            # clear gradients for this training step   \n",
        "            optimizer.zero_grad()\n",
        "            output = NeuralNet(images).to(torch.float64)\n",
        "            loss = criterion(output, labels.to(torch.float64))\n",
        "            # print(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()    # Does the update\n",
        "\n",
        "        # early_stopping needs the validation loss to check if it has decresed, and if it has, it will make a checkpoint of the current model\n",
        "        NeuralNet.eval()\n",
        "        test_output = torch.tensor([])\n",
        "        images, labels = loaders[\"val\"][:]\n",
        "        with torch.no_grad():\n",
        "          for imag, labe in loaders['val']:\n",
        "              test_out = NeuralNet(imag.to(torch.float32))\n",
        "\n",
        "              test_output = torch.cat((test_output,test_out.unsqueeze(0)),0)\n",
        "\n",
        "        acc0 = acc_for_class(0,labels, test_output)\n",
        "        acc1 = acc_for_class(1,labels, test_output)\n",
        "        acc2 = acc_for_class(2,labels, test_output)\n",
        "        early_stopping(1-(acc0+acc1+acc2)/3, NeuralNet)\n",
        "        print(\"accuracy mean: \", ((acc0+acc1+acc2)/3))\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            return early_stopping\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    pass\n",
        "\n",
        "\n",
        "def test(model):\n",
        "    # Test the model\n",
        "    model.eval()\n",
        "    test_output = torch.tensor([])\n",
        "    images, labels = loaders[\"test\"][:]\n",
        "    with torch.no_grad():\n",
        "        for imag, labe in loaders['test']:\n",
        "            test_out = model(imag.to(torch.float32))\n",
        "\n",
        "            test_output = torch.cat((test_output,test_out.unsqueeze(0)),0)\n",
        "        \n",
        "        # save_csv(images,\"input\") # nicht wirklich gebraucht\n",
        "        save_csv(test_output,\"predictions\")\n",
        "        \n",
        "        \n",
        "        strings = to_strings(labels)\n",
        "        t_np = np.array(strings) #convert to Numpy array\n",
        "        df = pd.DataFrame(t_np) #convert to a dataframe\n",
        "        df.to_csv(\"labels.csv\",index=False) #save to file\n",
        "\n",
        "        acc0 = acc_for_class(0,labels, test_output)\n",
        "        acc1 = acc_for_class(1,labels, test_output)\n",
        "        acc2 = acc_for_class(2,labels, test_output)\n",
        "        print(\"Hetero acc: \",acc0)\n",
        "        print(\"Homo acc: \",acc1)\n",
        "        print(\"Sing acc: \",acc2)\n",
        "        \n",
        "        import matplotlib.pyplot as plt\n",
        "        from sklearn.metrics import roc_curve, auc\n",
        "        # Compute ROC curve and ROC area for each class\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "        for i in range(3):\n",
        "            fpr[i], tpr[i], _ = roc_curve(labels[:, i].detach().numpy(), test_output[:, i].detach().numpy())\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "        # Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(labels.detach().numpy().ravel(), test_output.detach().numpy().ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "\n",
        "\n",
        "        plt.figure()\n",
        "        lw = 2\n",
        "        plt.plot(\n",
        "            fpr[2],\n",
        "            tpr[2],\n",
        "            color=\"darkorange\",\n",
        "            lw=lw,\n",
        "            label=\"ROC curve (area = %0.2f)\" % roc_auc[2],\n",
        "        )\n",
        "        plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel(\"False Positive Rate\")\n",
        "        plt.ylabel(\"True Positive Rate\")\n",
        "        plt.title(\"Receiver operating characteristic example\")\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    print('Test Accuracy of the model on test set: %.2f' % (1-(acc0+acc1+acc2)/3))\n",
        "    return (1-(acc0+acc1+acc2)/3)\n",
        "\n",
        "def acc_of_one_nn_run(NN):\n",
        "    nnet = NN\n",
        "    num_epochs = 100\n",
        "    ES = train(num_epochs, nnet, loaders)\n",
        "\n",
        "#    print(ES.best_model)\n",
        "\n",
        "\n",
        "    accuracy = test(ES.best_model)\n",
        "\n",
        "\n",
        "    # sample = next(iter(loaders['test']))\n",
        "    # imgs, lbls = sample\n",
        "\n",
        "    # actual_number = lbls[:10].numpy()\n",
        "    # actual_number\n",
        "\n",
        "    # test_output = ES.best_model(imgs[:10].float())\n",
        "    # pred_y = torch.max(test_output,-1)[1]\n",
        "    # print(f'Prediction number: {pred_y}')\n",
        "    # print(f'Actual number: {actual_number}')\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "acc_of_one_nn_run(ANNModel(100, 3))\n"
      ],
      "metadata": {
        "id": "Ybyxx1Nxn8Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "bs0BY4289PRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_of_one_nn_run(ANNModel, 4,3)"
      ],
      "metadata": {
        "id": "9XAzEnS3nwe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ANN\n",
        "ACCs = []\n",
        "ACCs.append(acc_of_one_nn_run(ANNModel, 4,3))\n",
        "ACCs.append(acc_of_one_nn_run(ANNModel, 4,3))\n",
        "ACCs.append(acc_of_one_nn_run(ANNModel, 4,3))\n",
        "ACCs.append(acc_of_one_nn_run(ANNModel, 4,3))\n",
        "ACCs.append(acc_of_one_nn_run(ANNModel, 4,3))\n",
        "\n",
        "print(\"Average accuracy of 5 ANNs: \", np.mean([i for i in ACCs]))\n",
        "\n"
      ],
      "metadata": {
        "id": "7vB1EEaJ2TSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CNN\n",
        "ACCs_c = []\n",
        "ACCs_c.append(acc_of_one_nn_run(CNN))\n",
        "ACCs_c.append(acc_of_one_nn_run(CNN))\n",
        "ACCs_c.append(acc_of_one_nn_run(CNN))\n",
        "ACCs_c.append(acc_of_one_nn_run(CNN))\n",
        "ACCs_c.append(acc_of_one_nn_run(CNN))\n",
        "\n",
        "\n",
        "print(\"Average accuracy of 5 CNNs: \", np.mean([i for i in ACCs_c]))"
      ],
      "metadata": {
        "id": "qz_g07MRyfm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "count free parameters"
      ],
      "metadata": {
        "id": "4vmhgJOB9XXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "ANN_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(ANN_params)\n",
        "CNN_params = sum(p.numel() for p in CNN().parameters() if p.requires_grad)\n",
        "print(\"Average accuracy of 5 CNNs: \", CNN_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzaaxVGg5vZ3",
        "outputId": "ed30434c-d3fd-4c10-cdae-583fce0a7ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "648010\n",
            "28938\n"
          ]
        }
      ]
    }
  ]
}